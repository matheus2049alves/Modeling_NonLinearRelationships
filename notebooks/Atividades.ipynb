{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Atividade 1"
      ],
      "metadata": {
        "id": "YqHVsUU_jvjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta atividade, você irá trabalhar com dados que apresentam padrões não lineares, como círculos ou luas, utilizando o scikit-learn para gerar o dataset e treinar diferentes modelos: um modelo linear (Logistic Regression), uma rede neural sem ativação (linear), e uma rede neural com função de ativação ReLU (não linear). Sua tarefa é completar as partes faltantes do código, ajustando os métodos de treinamento, acurácia e visualização, além de definir corretamente a função de ativação da MLP. Ao final, você irá visualizar a fronteira de decisão dos modelos e refletir sobre as diferenças de desempenho, entendendo por que as funções de ativação são essenciais para criar fronteiras complexas e como elas permitem que redes neurais resolvam problemas que modelos lineares não conseguem."
      ],
      "metadata": {
        "id": "4cRMRj_fjPwW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "d8GtVqm1gEpT",
        "outputId": "e5a09eba-57e2-4b91-d456-7ead758adf05"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (<ipython-input-1-4c2f6fb4962e>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4c2f6fb4962e>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    X, y = (n_samples=500, noise=0.1, random_state=42)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_circles, make_moons\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  Gerar um dataset complexo para classificação binária\n",
        "# TODO: Substitua ... pelo nome da função correta para gerar os dados (padrões não lineares)\n",
        "X, y = (n_samples=500, noise=0.1, random_state=42)\n",
        "\n",
        "#  Separar treino e teste\n",
        "# TODO: Implemente o split (dica: scikit-learn)\n",
        "X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "#  Treinar um modelo Linear (Logistic Regression)\n",
        "model_linear = LogisticRegression()\n",
        "model_linear.fit()\n",
        "acc_linear = accuracy_score(y_test, model_linear.predict(X_test))\n",
        "print(\"Acurácia Modelo Linear:\", acc_linear)\n",
        "\n",
        "#  Treinar uma rede neural sem ativação (Linear)\n",
        "# TODO: Defina corretamente a função de ativação no MLPClassifier\n",
        "model_nn_linear = MLPClassifier(hidden_layer_sizes=(10,), activation=________, max_iter=1000)\n",
        "model_nn_linear.fit()\n",
        "acc_nn_linear = accuracy_score()\n",
        "print(\"Acurácia MLP Linear:\", acc_nn_linear)\n",
        "\n",
        "#  Treinar uma rede neural com ativação não linear (ReLU)\n",
        "model_nn_relu = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', max_iter=1000)\n",
        "model_nn_relu.fit()\n",
        "acc_nn_relu = accuracy_score()\n",
        "print(\"Acurácia MLP com ReLU:\", acc_nn_relu)\n",
        "\n",
        "#  Visualizar a fronteira de decisão da rede não linear (ReLU)\n",
        "#  Implemente a visualização usando meshgrid, contourf, scatter Coloque os comentários nas partes faltando, e remova a numeração"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Atividade 2\n"
      ],
      "metadata": {
        "id": "SfpT4JUXjx5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta atividade, você irá trabalhar com dados que apresentam padrões não lineares, como círculos ou luas, utilizando o scikit-learn para gerar o dataset e treinar diferentes modelos: um modelo linear (Logistic Regression), uma rede neural sem ativação (linear), e uma rede neural com função de ativação ReLU (não linear). Sua tarefa é completar as partes faltantes do código, ajustando os métodos de treinamento, acurácia e visualização, além de definir corretamente a função de ativação da MLP. Ao final, você irá visualizar a fronteira de decisão dos modelos e refletir sobre as diferenças de desempenho, entendendo por que as funções de ativação são essenciais para criar fronteiras complexas e como elas permitem que redes neurais resolvam problemas que modelos lineares não conseguem. Além disso, gere o gráfico 3d da nova feature."
      ],
      "metadata": {
        "id": "qJ4SApmkj1AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️⃣ Gerar os dados do problema XOR\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# 2️⃣ Visualizar os dados no gráfico\n",
        "plt.scatter(X[:,0], X[:,1], c=y, cmap='coolwarm', s=100, edgecolors='k')\n",
        "plt.title(\"Dados XOR\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Criar manualmente a feature z = x1 * x2\n",
        "\n",
        "# Treinar o modelo linear com e sem a feature z\n",
        "# Modelo sem z\n",
        "model_linear =\n",
        "model_linear.fit()\n",
        "acc_without_z =\n",
        "\n",
        "# Modelo com z\n",
        "model_linear_z =\n",
        "model_linear_z.fit()\n",
        "acc_with_z = accuracy_score()\n",
        "\n",
        "# Visualização 3D\n"
      ],
      "metadata": {
        "id": "5WtVUprij_Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Atividade 3"
      ],
      "metadata": {
        "id": "M_5a9VywlN3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta atividade, você vai trabalhar com o dataset make_moons, que possui um padrão não linear. O objetivo é tentar resolver esse problema de classificação usando um modelo linear simples, mas criando manualmente algumas features novas para ver se isso ajuda a separar as classes. Depois, você vai comparar o desempenho desse modelo linear com o de uma rede neural MLP com função de ativação ReLU, que aprende automaticamente essas relações. Ao final, você deve comparar as acurácias e refletir sobre as dificuldades de criar features certas manualmente em problemas complexos."
      ],
      "metadata": {
        "id": "-sN837gXlPrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️⃣ Gerar dados com make_moons\n",
        "X, y =\n",
        "X_train, X_test, y_train, y_test =\n",
        "\n",
        "# 2️⃣ Adicionar features manuais\n",
        "x1 = X[:,0].reshape(-1,1)\n",
        "x2 = X[:,1].reshape(-1,1)\n",
        "x1_2 =\n",
        "x2_2 =\n",
        "x1x2 =\n",
        "X_extended =\n",
        "\n",
        "X_train_ext, X_test_ext, y_train_ext, y_test_ext = train_test_split(X_extended, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3️⃣ Modelos: Linear com features manuais vs. MLP (ReLU)\n",
        "model_linear = LogisticRegression()\n",
        "model_linear.fit()\n",
        "acc_linear = accuracy_score()\n",
        "\n",
        "model_mlp = MLPClassifier(hidden_layer_sizes=(10,), activation=, max_iter=1000)\n",
        "model_mlp.fit()\n",
        "acc_mlp =\n",
        "\n"
      ],
      "metadata": {
        "id": "GgNt_lP1lQYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Atividade 4"
      ],
      "metadata": {
        "id": "dUf5BHSLoLAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Nesta atividade, você vai aprender como as funções de ativação são importantes para as redes neurais. Seu desafio é:\n",
        "- Gerar dados com o make_moons.\n",
        "- Treinar uma rede neural sem funções de ativação (activation='identity'), mesmo com duas camadas ocultas.\n",
        "- Treinar uma outra rede com a função de ativação ReLU.\n",
        "- Comparar a acurácia dos dois modelos.\n",
        "- Visualizar a fronteira de decisão da rede com ReLU.\n",
        "\n",
        "No final, responda: Por que a rede sem ativação se comporta como um modelo linear, mesmo com várias camadas?\n"
      ],
      "metadata": {
        "id": "XVE2d5OgoMeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Gerar dados com make_moons\n",
        "X, y =\n",
        "X_train, X_test, y_train, y_test =\n",
        "\n",
        "# Treinar uma MLP sem ativação (linear), com 2 camadas ocultas\n",
        "model_linear =\n",
        "model_linear.fit()\n",
        "acc_linear =\n",
        "\n",
        "# Treinar uma MLP com ReLU nas mesmas condições\n",
        "model_relu =\n",
        "model_relu.fit()\n",
        "acc_relu =\n",
        "# Visualizar as fronteiras de decisão (para o modelo com ReLU)\n",
        "xx, yy =\n",
        "grid =\n",
        "Z_relu =\n",
        "\n"
      ],
      "metadata": {
        "id": "0T3Tg1EfoMzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Local de Resposta:"
      ],
      "metadata": {
        "id": "Jn7yZ6MborXU"
      }
    }
  ]
}